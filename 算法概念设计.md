### **算法概念设计**

现在有一个数学问题数据集，规定有以下操作：

1. 拆分问题：可以将问题拆分成若干的前提与提问
2. 消去前提：将问题中的一个前提消去
3. 交叉问题：将两个问题中的前提与提问交换

已知：大模型在面对逻辑混乱的问题，会出现过度思考的现象

目标：使用遗传算法优化输入问题，使得输入对大模型的输出回复token数量最多

首先，我们需要定义算法的几个核心要素：

- **个体 (Individual)**：一个独立的数学问题。为了方便操作，我们应将其结构化表示，例如：`{premises: ["前提1", "前提2", ...], question: "提问"}`。
- **种群 (Population)**：一组“个体”（数学问题）的集合。
- **适应度函数 (Fitness Function)**：这是评价一个个体优劣的核心标准。在这里，**适应度 = LLM对该问题回复的Token数量**。分数越高，代表这个问题的“逻辑混乱度”可能越高，越能引发模型的“过度思考”。
- **基因操作 (Genetic Operators)**：
  - **交叉 (Crossover)**：对应定义的“交叉问题”操作。
  - **变异 (Mutation)**：对应“消去前提”，也可以包括其他随机改变（如随机组合不同问题的前提）。

### **遗传算法核心循环 (Loop) 设计**

假设我们已经有了一个初始的数学问题种群（从数据集中选取并进行了初始的“拆分问题”操作，使其结构化）。

**循环开始：** 对于预设的每一代（Generation）：

------



#### **第1步：适应度评估 (Fitness Evaluation)**

这是循环中最关键也是计算成本最高的一步。

1. **遍历种群**：取出当前种群中的每一个问题（个体）。
2. **格式化输入**：将结构化的问题 `{premises, question}` 重新组合成一个完整的文本字符串，作为对大模型的输入。例如：“已知[前提1]，[前提2]，...，请问[提问]？”。
3. **调用LLM**：将这个文本字符串发送给您指定的大模型。
4. **计算适应度**：获取模型的回复，并**计算回复内容的Token数量**。这个数量就是该问题的适应度分数。
5. **记录分数**：将计算出的适应度分数与该问题关联起来。

*在这一步结束后，当前种群中的每一个问题都有了一个明确的“优劣”得分。*

------



#### **第2步：选择 (Selection)**



此步骤的目的是“优胜劣汰”，选出优秀的父代来繁殖下一代。

1. **精英保留 (Elitism)**：将当前种群中适应度分数最高的 `N` 个问题直接复制到下一代种群中。这可以确保我们在进化过程中不会丢失已经发现的最优解。
2. **父代选择 (Parent Selection)**：对于剩余需要填充的名额，我们从当前种群中选择“父代”。通常采用**轮盘赌选择法**：
   - 每个问题的适应度分数越高，它被选为父代的概率就越大。
   - 通过这种方式，我们既保证了优秀基因的延续，也给了非最优解一定的机会，增加了种群的多样性。

------



#### **第3步：交叉与变异 (Crossover and Mutation)**



这是创造新一代个体的核心步骤，旨在通过基因重组和随机改变来探索新的、可能更优的问题组合。

1. **配对**：将上一步选出的父代两两配对。
2. **交叉操作**：以一个较高的“交叉概率”（如 `80%`）对这对父代执行“**交叉问题**”操作。
   - **问题 A**: `{premises_A, question_A}`
   - **问题 B**: `{premises_B, question_B}`
   - 通过交换它们的前提或提问，生成两个新的子代问题。例如：
     - **子代 C**: `{premises_A, question_B}`
     - **子代 D**: `{premises_B, question_A}`
   - 如果未触发交叉，则父代直接成为子代。
3. **变异操作**：对交叉后生成的每个子代，再以一个较低的“变异概率”（如 `10%`）执行变异操作。
   - **执行“消去前提”**：随机选择子代问题的一个前提并将其删除。这个操作是制造逻辑不连贯、增加“混乱度”的直接手段。
   - （可选）可以设计更丰富的变异操作，例如从种群中另一个随机问题里“偷”一个前提添加进来，进一步增加混乱度。

------



#### **第4b步：形成新一代种群 (Form New Population)**



将通过“精英保留”和“交叉与变异”产生的所有新问题组合在一起，形成一个规模与上一代相同的新种群。

------

**循环结束：**

这个新种群将取代旧种群，进入下一代的循环，重复执行“适应度评估 → 选择 → 交叉与变异”的整个过程。

当循环达到预设的代数后，算法停止。此时，在所有代中出现过的适应度分数最高（即引发LLM回复Token数最多）的那个问题，就是我们最终找到的最优解。